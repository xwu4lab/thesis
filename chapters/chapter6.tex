\chapter{CONCLUSION AND FUTURE RESEARCH}

\section{Conclusion}
This thesis investigates state-of-the-art \acrshort{vslam} paradigms on outdoor robotic applications, e.g. smart farming, environmental monitoring, and autonomous driving.
In general, the short-term illumination-robustness and long-term appearance-robustness play vital roles in pushing the applicability of outdoor \acrshort{vslam} forward. 
Multiple algorithmic components of \acrshort{vslam} are investigated and improved in this thesis, where the key contributions are summarized:

\begin{enumerate}
	\item[\textbf{Delay-Insensitive Multi-Object Multi-Camera Tracking.}] To facilitate the automated weed control system, a delay-insensitive multi-object multi-camera tracking algorithm is proposed to provide weed/plant tracking in the presence of indeterminant classification delays. The proposed system can be divided into a monocular-sonar metric \acrshort{vo}, an illumination-robust 3D-2D inter-camera tracker, and an object management module. The monocular-sonar metric \acrshort{vo}, namely intra-camera tracking, recovers the camera motion and 3D model of weed/plant for tracking. The illumination-robust object tracker incorporates an illumination-robust cost to rule out the appearance changes across cameras due to lighting differences. To ease the object management under the indeterminate classification delays caused by the plant detection algorithms, an object management module is designed to initialize delayed objects, formulate the patch-based descriptor, and update it across the camera. Finally, an integrated weed control system integrating the proposed tracker, weed/plant classifier, and a predictive controller, is developed for fast and accurate weed removal.
	\item[\textbf{Illumination-Robust Direct Visual Odometry.}] The idea of illumination robustness are introduced to direct formulation of \acrshort{vslam}/\acrshort{vo} pipelines. State-of-the-art illumination-robust costs are investigated and evaluated in the context of \acrshort{vo} optimization framework using a synthetic dataset with simulated light changes. Based on our analysis, the affine-model- and gradient-based energy functions are selected and dynamically combined through a convergence-preserved reweighting strategy for illumination-robust localization. We further present a brief evaluation of the mapping performance using images affected by solar glare, which illustrates that the sun glare can be modeled as local illumination changes and its adverse effect on motion estimation can be alleviated by introducing an algorithm robust to such local changes.
	\item[\textbf{Illumination-Robust Edge Visual Odometry}] To overcome the small region of attraction issue induced by direct image alignment, the edge-based registration is used as the substitution of the direct formulation. Correspondingly, an illumination-robust edge \acrshort{vo} system is developed to exploit the edge features and image gradient for illumination-robust camera motion estimation and scene reconstruction. These are obtained by an edge alignment front-end, a finer point correspondence refinement strategy through a fast probabilistic 1D search strategy, and joint optimization in local bundle adjustment. The proposed system successfully overcomes the partial observability issue of monocular edge mapping as well as improving the robustness of outdoor motion estimation.
	\item[\textbf{Semantics-Aided Edge Visual Odometry}] A semantic extension is proposed to further boost our edge \acrshort{vo} performance. Specifically, we present a monocular semantic edge \acrshort{vo} framework that is capable of reconstructing 3D semantic edge maps in unstructured outdoor environments. Our proposed SNNFs offer several advantages over existing edge \acrshort{vo} algorithms by using deep-learned semantic as a robust data association strategy. We analyze the influence of edge-learning and alignment methods on edge-based motion estimation and overcome the primary limitations of edge \acrshort{vo} for outdoor application. 
	\item[\textbf{Semantics-Aided Cross-Season Localization}] A single-network design, {\em DLSSNet}, with explicit semantic and geometric feature learning branches that extracted feature information from across multiple layers of the network and fused them according to best design principles. The intent is to explicitly enable the learning of multi-level (high and low) representations from the training imagery. A decoupled then coupled, the multi-stage training process was described that lowers human annotation demands yet still enables coupled learning of the multi-level descriptors. The resulting network achieved strong performance on cross-season localization. The city-centered semantic datasets used significantly constrain the training corpus. Therefore, all datasets used here concentrate on autonomous driving applications either within or across seasons.
\end{enumerate}


\section{Future Research}
Although this thesis makes progress in developing short-term illumination-robust \acrshort{vo} pipelines that generates reliable locally consistent maps, adapting such systems, either direct or edge-based formulas, to reuse existing information from a reconstructed map is still challenging. 
Without loop-closing, \acrshort{vo} systems suffer from the accumulated drift that deteriorates the global mapping accuracy and thus limits their long-term usage. 
In order to close loops, indexed image features, e.g. Bag-of-Words (BoWs), are typically used to perform loop candidate detection. 
However, such methods are tightly related to certain types of features, which generally inapplicable for direct or edge-based approaches. 
Alternatively, image proximity, e.g. deep image retrieval, can be applied for loop candidate detection tasks.
However, it is usually at the price of increasing computation and memory load, which may require additional computational resources on-board for real-time performance.  
Overall speaking, both potential solutions are foreseen to face a certain level of challenges, which prohibits the delivery of a full pipeline of edge-based \acrshort{vslam} within this thesis. 

Besides, this thesis presents a deep neural network, {\em DLSSNet}, for cross-season visual localization. 
Although it shows some interesting results in cross-seasonal cases, this thesis fails to include further analysis of other challenging situations, e.g. day-night, cross-weather cases. 
It is the city-centered semantic datasets used that significantly constrain the training corpus.  
Therefore, all datasets used here concentrate on autonomous driving applications either within or across seasons.  
Other day-night and cross-weather localization datasets that do not match the setting cannot be applied, which is an opportunity for further study.
Due to such limitations, the future evaluation of the proposed method is desired when such semantic segmentation datasets are available.